// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
import {noteContent} from "./external-tokens.js"
export const parser = LRParser.deserialize({
  version: 14,
  states: "!jQQOPOOOVOPO'#C`O[OQO'#C_OOOO'#Cc'#CcQQOPOOOaOPO,58zOOOO,58y,58yOOOO-E6a-E6aOfOPO1G.fOOOQ7+$Q7+$QOnOPO7+$QOOOQ<<Gl<<Gl",
  stateData: "s~OXPO~OYTO~OPUO~OTWO~OUYOXXO~OXZO~O",
  goto: "gWPPPX]PPaTROSTQOSQSORVS",
  nodeNames: "âš  NoteContent Document Note NoteDelimiter NoteLanguage Auto",
  maxTerm: 10,
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData: ".R~RbYZ!Z}!O!`#V#W!k#W#X$X#X#Y$z#Z#[%j#[#]&]#^#_&o#_#`(V#`#a(o#a#b)X#d#e*W#f#g+r#g#h,R#h#i,k#l#m&c#m#n-j%&x%&y-p~!`OX~~!cP#T#U!f~!kOU~~!nR#`#a!w#d#e#l#g#h#r~!zP#c#d!}~#QP#^#_#T~#WP#i#j#Z~#^P#f#g#a~#dP#X#Y#g~#lOT~~#oP#d#e#g~#uQ#[#]#{#g#h#g~$OP#T#U$R~$UP#f#g#l~$[Q#T#U$b#]#^$n~$eP#f#g$h~$kP#h#i#g~$qP#Y#Z$t~$wP#Y#Z#g~$}P#f#g%Q~%TP#`#a%W~%ZP#T#U%^~%aP#b#c%d~%gP#Z#[#g~%mQ#c#d%Q#f#g%s~%vP#c#d%y~%|P#c#d&P~&SP#j#k&V~&YP#m#n#g~&`P#h#i&c~&fP#a#b&i~&lP#`#a#g~&rQ#T#U&x#g#h'v~&{P#j#k'O~'RP#T#U'U~'ZPT~#g#h'^~'aP#V#W'd~'gP#f#g'j~'mP#]#^'p~'sP#d#e$h~'yQ#c#d(P#l#m#g~(SP#b#c#g~(YP#c#d(]~(`P#h#i(c~(fP#`#a(i~(lP#]#^(P~(rP#X#Y(u~(xP#n#o({~)OP#X#Y)R~)UP#f#g#g~)[P#T#U)_~)bQ#f#g)h#h#i*Q~)kP#_#`)n~)qP#W#X)t~)wP#c#d)z~)}P#k#l(P~*TP#[#]#g~*ZR#[#]#l#c#d*d#m#n+`~*gP#k#l*j~*mP#X#Y*p~*sP#f#g*v~*yP#g#h*|~+PP#[#]+S~+VP#X#Y+Y~+]P#`#a&i~+cP#h#i+f~+iP#[#]+l~+oP#c#d(P~+uP#i#j+x~+{Q#U#V&V#g#h$h~,UR#[#]+S#e#f&i#k#l,_~,bP#]#^,e~,hP#Y#Z$h~,nS#X#Y,z#c#d&c#g#h-Q#m#n-W~,}P#l#m$h~-TP#l#m#g~-ZP#d#e-^~-aP#X#Y-d~-gP#g#h'^~-mP#T#U&c~-sP%&x%&y-v~-yP%&x%&y-|~.ROY~",
  tokenizers: [0, noteContent],
  topRules: {"Document":[0,2]},
  tokenPrec: 0
})
